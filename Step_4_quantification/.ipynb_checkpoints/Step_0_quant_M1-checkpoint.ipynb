{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb1dd51-80d2-4e15-9f32-845276e7c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.transforms as transforms\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import metrics\n",
    "from math import pi\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ee1462-7aab-490a-9f66-b0af459d95ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((363, 19, 64, 64, 1),\n",
       " (363, 19, 64, 64, 1),\n",
       " (363, 18, 64, 64, 1),\n",
       " (363, 18, 64, 64, 1),\n",
       " (363, 17, 64, 64, 1),\n",
       " (363, 17, 64, 64, 1),\n",
       " (363, 16, 64, 64, 1),\n",
       " (363, 16, 64, 64, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Loading all 4 generations of Predicted and Ground Truth validaiton dataset of Model 2\n",
    "path = os.path.abspath('..')\n",
    "\n",
    "M1_GT_G0,  M1_PD_G0  = np.load(path+'/Step_3_predictions/model_1_results/GEN-0.npy',) # allow_pickle=True)\n",
    "M1_GT_G1,  M1_PD_G1  = np.load(path+'/Step_3_predictions/model_1_results/GEN-1.npy',) # allow_pickle=True)\n",
    "M1_GT_G2,  M1_PD_G2  = np.load(path+'/Step_3_predictions/model_1_results/GEN-2.npy',) # allow_pickle=True)\n",
    "M1_GT_G3,  M1_PD_G3  = np.load(path+'/Step_3_predictions/model_1_results/GEN-3.npy',) # allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "def scale_array(arr):\n",
    "    arr_min = np.min(arr)  ## Flattens the array and finds the min value inside it\n",
    "    arr_max = np.max(arr)  ## Flattens the array and finds the max value inside it\n",
    "    scaled_array = (arr - arr_min) / (arr_max - arr_min) * 255\n",
    "    scaled_array = scaled_array.astype(np.uint8)\n",
    "    \n",
    "    return scaled_array\n",
    "\n",
    "M1_GT_G0_scaled, M1_PD_G0_scaled = scale_array(M1_GT_G0), scale_array(M1_PD_G0)\n",
    "M1_GT_G1_scaled, M1_PD_G1_scaled = scale_array(M1_GT_G1), scale_array(M1_PD_G1)\n",
    "M1_GT_G2_scaled, M1_PD_G2_scaled = scale_array(M1_GT_G2), scale_array(M1_PD_G2)\n",
    "M1_GT_G3_scaled, M1_PD_G3_scaled = scale_array(M1_GT_G3), scale_array(M1_PD_G3)\n",
    "\n",
    "M1_GT_G0.shape, M1_PD_G0.shape, M1_GT_G1.shape, M1_PD_G1.shape, M1_GT_G2.shape, M1_PD_G2.shape, M1_GT_G3.shape, M1_PD_G3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21eb805-ec27-40e5-bbc7-7ce7bc20cf00",
   "metadata": {},
   "source": [
    "## Calculation of RMSE and $\\mu_{SIM}$ for Model Architecture 1 Prediction in two generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b173b1-df91-4b91-9149-32a64ca97ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d, e = M1_GT_G0.shape[0], M1_GT_G0.shape[1], M1_GT_G0.shape[2], M1_GT_G0.shape[3], M1_GT_G0.shape[4] \n",
    "\n",
    "## For Individual Image Frames\n",
    "rmse_g0 = np.zeros((a,b))\n",
    "ssim_g0 = np.zeros((a,b))\n",
    "\n",
    "for i in range(M1_GT_G0_scaled.shape[0]):\n",
    "  for j in range(M1_GT_G0_scaled.shape[1]):\n",
    "    rmse_g0[i][j] = metrics.normalized_root_mse(M1_GT_G0_scaled[i,j,:,:,0], M1_PD_G0_scaled[i,j,:,:,0])\n",
    "    ssim_g0[i][j] = metrics.structural_similarity(M1_GT_G0_scaled[i,j,:,:,0], M1_PD_G0_scaled[i,j,:,:,0], win_size=3)\n",
    "\n",
    "\n",
    "## For Individual Video Sequence (17 frames)\n",
    "rmse_g0_vs = np.zeros((a))\n",
    "ssim_g0_vs = np.zeros((a))\n",
    "\n",
    "for i in range(M1_GT_G0_scaled.shape[0]):\n",
    "  # for j in range(M1_GT_G0_scaled.shape[1]):\n",
    "  rmse_g0_vs[i] = metrics.normalized_root_mse(M1_GT_G0_scaled[i,:,:,:,0], M1_PD_G0_scaled[i,:,:,:,0])\n",
    "  ssim_g0_vs[i] = metrics.structural_similarity(M1_GT_G0_scaled[i,:,:,:,0], M1_PD_G0_scaled[i,:,:,:,0], win_size=3)\n",
    "\n",
    "\n",
    "rmse_g0_all = metrics.normalized_root_mse(M1_GT_G0_scaled, M1_PD_G0_scaled)\n",
    "ssim_g0_all = metrics.structural_similarity(M1_GT_G0_scaled[:,:,:,:,0], M1_PD_G0_scaled[:,:,:,:,0], win_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b60bd7-314d-4040-bfca-5eb6f12f4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d, e = M1_GT_G1.shape[0], M1_GT_G1.shape[1], M1_GT_G1.shape[2], M1_GT_G1.shape[3], M1_GT_G1.shape[4] \n",
    "\n",
    "## For Individual Image Frames\n",
    "rmse_g1 = np.zeros((a,b))\n",
    "ssim_g1 = np.zeros((a,b))\n",
    "\n",
    "for i in range(M1_GT_G1_scaled.shape[0]):\n",
    "  for j in range(M1_GT_G1_scaled.shape[1]):\n",
    "    rmse_g1[i][j] = metrics.normalized_root_mse(M1_GT_G1_scaled[i,j,:,:,0], M1_PD_G1_scaled[i,j,:,:,0])\n",
    "    ssim_g1[i][j] = metrics.structural_similarity(M1_GT_G1_scaled[i,j,:,:,0], M1_PD_G1_scaled[i,j,:,:,0], win_size=3)\n",
    "\n",
    "## For Individual Video Sequence (17 frames)\n",
    "rmse_g1_vs = np.zeros((a))\n",
    "ssim_g1_vs = np.zeros((a))\n",
    "\n",
    "for i in range(M1_GT_G1_scaled.shape[0]):\n",
    "  # for j in range(M1_GT_G1_scaled.shape[1]):\n",
    "  rmse_g1_vs[i] = metrics.normalized_root_mse(M1_GT_G1_scaled[i,:,:,:,0], M1_PD_G1_scaled[i,:,:,:,0])\n",
    "  ssim_g1_vs[i] = metrics.structural_similarity(M1_GT_G1_scaled[i,:,:,:,0], M1_PD_G1_scaled[i,:,:,:,0], win_size=3)\n",
    "\n",
    "\n",
    "## For ALL Validation set at once\n",
    "rmse_g1_all = metrics.normalized_root_mse(M1_GT_G1_scaled, M1_PD_G1_scaled)\n",
    "ssim_g1_all = metrics.structural_similarity(M1_GT_G1_scaled[:,:,:,:,0], M1_PD_G1_scaled[:,:,:,:,0], win_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bb16629-f62a-454e-9e45-0da18fa49217",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_list = [ssim_g0_vs.tolist(), ssim_g1_vs.tolist(), [ssim_g0_all], [ssim_g1_all.tolist()], rmse_g0_vs.tolist(), rmse_g1_vs.tolist(), [rmse_g0_all.tolist()], [rmse_g1_all.tolist()] ]\n",
    "\n",
    "max_len = max(len(inner_list) for inner_list in array_list)\n",
    "\n",
    "ssim_rmse_2gens_A1 = np.zeros((len(array_list), max_len), dtype=float)\n",
    "\n",
    "for i, inner_list in enumerate(array_list):\n",
    "    ssim_rmse_2gens_A1[i, :len(inner_list)] = inner_list\n",
    "\n",
    "np.save(path+'/Step_4_quantification/Step_3_best_model_selection/ssim_rmse_2gens_A1.npy', ssim_rmse_2gens_A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8043f-91aa-4993-ab79-6f476dd62da8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
