{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa7e19c-772d-4807-856a-8c5006984d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "703af18e-8d2b-472a-bb25-1d5b549529f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137, 17, 64, 64, 3), (137, 17, 64, 64, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.abspath(\"..\")\n",
    "\n",
    "X_val = np.load(path+\"/train_test_data/X_val.npy\")\n",
    "y_val = np.load (path+\"/train_test_data/y_val.npy\")\n",
    "\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e7faff-a000-4b24-9954-4243eb524a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = load_model(path+\"/predictions/trained_model.h5\")\n",
    "history = np.load(path+\"/predictions/model_history.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82fb6f3-1e87-4dd9-a584-caa5ff8dce73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_array(arr):\n",
    "    arr_min = np.min(arr)  ## Flattens the array and finds the min value inside it\n",
    "    arr_max = np.max(arr)  ## Flattens the array and finds the max value inside it\n",
    "    scaled_array = (arr - arr_min) / (arr_max - arr_min) * 255\n",
    "    scaled_array = scaled_array.astype(np.uint8)\n",
    "    \n",
    "    return scaled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "767a0fe2-d12e-4acb-9bfa-f625d8ca9c08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137, 17, 64, 64, 1), (137, 17, 64, 64, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT_array = y_val\n",
    "a, b, c, d, e = y_val.shape[0], y_val.shape[1], y_val.shape[2], y_val.shape[3], y_val.shape[4] \n",
    "PD_array = np.zeros((a, b, c, d, e))   ## Predicted arrays\n",
    "\n",
    "for i in range(X_val.shape[0]):\n",
    "    frames = X_val[i]   ## taking 1 validation video sample at one time\n",
    "    PD_array[i] = model.predict(np.expand_dims(frames, axis=0), verbose=0, workers=10, use_multiprocessing=True)\n",
    "\n",
    "GT_scaled = scale_array(y_val)\n",
    "PD_scaled = scale_array(PD_array)\n",
    "\n",
    "GT_array.shape, PD_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa2a008d-9b32-4eab-9076-deb059b4ddf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137, 16, 64, 64, 1), (137, 16, 64, 64, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_g1 = np.delete(np.concatenate((X_val, PD_array), axis=-1), 0, axis=-1)\n",
    "X_g1 = np.delete(X_g1, -1, axis=1)\n",
    "y_g1 = np.delete(y_val, 0, axis=1)\n",
    "\n",
    "a, b, c, d, e = y_g1.shape[0], y_g1.shape[1], y_g1.shape[2], y_g1.shape[3], y_g1.shape[4] \n",
    "PD_G1 = np.zeros((a, b, c, d, e))   ## Predicted arrays\n",
    "for i in range(X_g1.shape[0]):\n",
    "    frames = X_g1[i]   ## taking 1 validation video sample at one time\n",
    "    PD_G1[i] = model.predict(np.expand_dims(frames, axis=0), verbose=0, workers=10, use_multiprocessing=True)\n",
    "\n",
    "y_g1_scaled = scale_array(y_g1)\n",
    "PD_G1_scaled = scale_array(PD_G1)\n",
    "\n",
    "y_g1.shape, PD_G1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef3a9770-0cb3-4801-85ae-51ba549a1e82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137, 15, 64, 64, 1), (137, 15, 64, 64, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_g2 = np.delete(np.concatenate((X_g1, PD_G1), axis=-1), 0, axis=-1)\n",
    "X_g2 = np.delete(X_g2, -1, axis=1)\n",
    "y_g2 = np.delete(y_g1, 0, axis=1)\n",
    "\n",
    "a, b, c, d, e = y_g2.shape[0], y_g2.shape[1], y_g2.shape[2], y_g2.shape[3], y_g2.shape[4] \n",
    "PD_G2 = np.zeros((a, b, c, d, e))   ## Predicted arrays\n",
    "\n",
    "for i in range(X_g1.shape[0]):\n",
    "    frames = X_g2[i]   ## taking 1 validation video sample at one time\n",
    "    PD_G2[i] = model.predict(np.expand_dims(frames, axis=0), verbose=0, workers=10, use_multiprocessing=True)\n",
    "\n",
    "y_g2_scaled = scale_array(y_g2)\n",
    "PD_G2_scaled = scale_array(PD_G2)\n",
    "\n",
    "y_g2.shape, PD_G2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8befb1e3-eac2-4357-93d3-ceb1508c192b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137, 14, 64, 64, 1), (137, 14, 64, 64, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_g3 = np.delete(np.concatenate((X_g2, PD_G2), axis=-1), 0, axis=-1)\n",
    "X_g3 = np.delete(X_g3, -1, axis=1)\n",
    "y_g3 = np.delete(y_g2, 0, axis=1)\n",
    "\n",
    "a, b, c, d, e = y_g3.shape[0], y_g3.shape[1], y_g3.shape[2], y_g3.shape[3], y_g3.shape[4] \n",
    "PD_G3 = np.zeros((a, b, c, d, e))   ## Predicted arrays\n",
    "\n",
    "for i in range(X_g2.shape[0]):\n",
    "    frames = X_g3[i]   ## taking 1 validation video sample at one time\n",
    "    PD_G3[i] = model.predict(np.expand_dims(frames, axis=0), verbose=0, workers=10, use_multiprocessing=True)\n",
    "\n",
    "y_g3_scaled = scale_array(y_g3)\n",
    "PD_G3_scaled = scale_array(PD_G3)\n",
    "\n",
    "y_g3.shape, PD_G3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e2cff23-81ce-49e0-aa88-9dd260867a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path+'/predictions/GEN-0.npy', [GT_array, PD_array])\n",
    "np.save(path+'/predictions/GEN-1.npy', [y_g1, PD_G1])\n",
    "np.save(path+'/predictions/GEN-2.npy', [y_g2, PD_G2])\n",
    "np.save(path+'/predictions/GEN-3.npy', [y_g3, PD_G3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044de5f-821e-4dd7-87b7-d4f2a5093c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
